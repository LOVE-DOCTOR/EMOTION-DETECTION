{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0456d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling1D, Embedding, Conv1D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import neattext.functions as nfx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras_nlp\n",
    "from keras_nlp.tokenizers import WordPieceTokenizer\n",
    "from keras_nlp.layers import TokenAndPositionEmbedding, TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe35bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as f:\n",
    "    df = f.readlines()\n",
    "\n",
    "with open('test.txt', 'r') as kk:\n",
    "    c = kk.readlines()\n",
    "\n",
    "\n",
    "for i in c:\n",
    "    df.append(i)\n",
    "\n",
    "with open('val.txt', 'r') as mm:\n",
    "    valid = mm.readlines()\n",
    "\n",
    "\n",
    "new_df = [i.split(';') for i in df]\n",
    "validate = [i.split(';') for i in valid]\n",
    "\n",
    "text = list()\n",
    "label = list()\n",
    "for i in new_df:\n",
    "    for j in i:\n",
    "        if '\\n' not in j:\n",
    "            text.append(j)\n",
    "        else:\n",
    "            label.append(j)\n",
    "\n",
    "            \n",
    "text_valid, label_valid = list(), list()\n",
    "for i in validate:\n",
    "    for j in i:\n",
    "        if '\\n' not in j:\n",
    "            text_valid.append(j)\n",
    "        else:\n",
    "            label_valid.append(j)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data_valid = pd.DataFrame()\n",
    "\n",
    "data['text'] = text\n",
    "data['label'] = [i.replace('\\n', '') for i in label]\n",
    "\n",
    "data_valid['text_valid'] = text_valid\n",
    "data_valid['label_valid'] = [i.replace('\\n', '') for i in label_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672eb71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "17995  i just keep feeling like someone is being unki...    anger\n",
       "17996  im feeling a little cranky negative after this...    anger\n",
       "17997  i feel that i am useful to my people and that ...      joy\n",
       "17998  im feeling more comfortable with derby i feel ...      joy\n",
       "17999  i feel all weird when i have to meet w people ...     fear\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446e1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(lem.lemmatize(word) for word in x.split()))\n",
    "data_valid['text_valid'] = data_valid['text_valid'].apply(lambda x: ' '.join(lem.lemmatize(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129e84b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feeling hopeless damned hopeful care awake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling nostalgic fireplace know property</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>feeling like unkind wrong think people close</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>im feeling little cranky negative doctor appoi...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>feel useful people great feeling achievement</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>im feeling comfortable derby feel start step s...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>feel weird meet w people text like dont talk f...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label\n",
       "0                                  didnt feel humiliated  sadness\n",
       "1             feeling hopeless damned hopeful care awake  sadness\n",
       "2              im grabbing minute post feel greedy wrong    anger\n",
       "3              feeling nostalgic fireplace know property     love\n",
       "4                                        feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "17995       feeling like unkind wrong think people close    anger\n",
       "17996  im feeling little cranky negative doctor appoi...    anger\n",
       "17997       feel useful people great feeling achievement      joy\n",
       "17998  im feeling comfortable derby feel start step s...      joy\n",
       "17999  feel weird meet w people text like dont talk f...     fear\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']= data['text'].apply(nfx.remove_stopwords)\n",
    "data_valid['text_valid'] = data_valid['text_valid'].apply(nfx.remove_stopwords)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8956432a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         6057\n",
       "sadness     5247\n",
       "anger       2434\n",
       "fear        2161\n",
       "love        1463\n",
       "surprise     638\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae15a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {'joy': 0,\n",
    "            'sadness': 1,\n",
    "            'anger': 2,\n",
    "            'fear': 3,\n",
    "            'love': 4,\n",
    "            'surprise': 5}\n",
    "data['label'] = data['label'].map(emotions)\n",
    "data_valid['label_valid'] = data_valid['label_valid'].map(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6cc7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feeling hopeless damned hopeful care awake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling nostalgic fireplace know property</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>feeling like unkind wrong think people close</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>im feeling little cranky negative doctor appoi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>feel useful people great feeling achievement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>im feeling comfortable derby feel start step s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>feel weird meet w people text like dont talk f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                  didnt feel humiliated      1\n",
       "1             feeling hopeless damned hopeful care awake      1\n",
       "2              im grabbing minute post feel greedy wrong      2\n",
       "3              feeling nostalgic fireplace know property      4\n",
       "4                                        feeling grouchy      2\n",
       "...                                                  ...    ...\n",
       "17995       feeling like unkind wrong think people close      2\n",
       "17996  im feeling little cranky negative doctor appoi...      2\n",
       "17997       feel useful people great feeling achievement      0\n",
       "17998  im feeling comfortable derby feel start step s...      0\n",
       "17999  feel weird meet w people text like dont talk f...      3\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba7fbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=4000)\n",
    "token.fit_on_texts(data['text'])\n",
    "vocab = ['[UNK]']\n",
    "for i, j in token.word_index.items():\n",
    "    vocab.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54fc21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPieceTokenizer(vocabulary=vocab, sequence_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46bc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "#token.fit(data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52755f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
    "X_valid = data_valid['text_valid']\n",
    "y_valid = data_valid['label_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f2242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = tokenizer(X_train)\n",
    "X_test_ = tokenizer(X_test)\n",
    "X_valid_ = tokenizer(X_valid)\n",
    "\n",
    "#X_train_ = token.transform(X_train).astype('float16')\n",
    "#X_test_ = token.transform(X_test).astype('float16')\n",
    "#X_valid_ = token.transform(X_valid).astype('float16')\n",
    "\n",
    "\n",
    "y_train_ = to_categorical(y_train)\n",
    "y_test_ = to_categorical(y_test)\n",
    "y_valid_ = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aea8fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14400, 20), dtype=int32, numpy=\n",
       "array([[ 120,   26,    3, ...,    0,    0,    0],\n",
       "       [   1,    3,    4, ...,    0,    0,    0],\n",
       "       [   5, 4280, 7946, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,  640,    0, ...,    0,    0,    0],\n",
       "       [   5,  162,    1, ...,    0,    0,    0],\n",
       "       [   1,   87,  140, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d3a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f8146",
   "metadata": {},
   "source": [
    "vocab_size = len(token.word_index) + 1 \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46de1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_and_position_embeddin  (None, None, 128)        1813120   \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_encoder (Transf  (None, None, 128)        99584     \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,913,478\n",
      "Trainable params: 1,913,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(None,)))\n",
    "\n",
    "model.add(TokenAndPositionEmbedding(vocabulary_size=len(vocab), sequence_length=20, embedding_dim=128))\n",
    "\n",
    "model.add(TransformerEncoder(num_heads=8, intermediate_dim=128, dropout=0.2, activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['CategoricalAccuracy', 'accuracy', 'AUC', 'Precision', 'Recall'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a3c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#estimator = KerasClassifier(build_fn=model(), epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f5fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = EarlyStopping(monitor = 'val_loss', \n",
    "                          patience = 5, \n",
    "                          verbose = 6,\n",
    "                          restore_best_weights = True,\n",
    "                          mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f5872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "720/720 [==============================] - 36s 46ms/step - loss: 1.0966 - categorical_accuracy: 0.5865 - accuracy: 0.5865 - auc: 0.8746 - precision: 0.7920 - recall: 0.4240 - val_loss: 0.3488 - val_categorical_accuracy: 0.8910 - val_accuracy: 0.8910 - val_auc: 0.9844 - val_precision: 0.9032 - val_recall: 0.8815\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 30s 41ms/step - loss: 0.2145 - categorical_accuracy: 0.9240 - accuracy: 0.9240 - auc: 0.9939 - precision: 0.9305 - recall: 0.9173 - val_loss: 0.2793 - val_categorical_accuracy: 0.9030 - val_accuracy: 0.9030 - val_auc: 0.9902 - val_precision: 0.9076 - val_recall: 0.8985\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 30s 42ms/step - loss: 0.1070 - categorical_accuracy: 0.9602 - accuracy: 0.9602 - auc: 0.9981 - precision: 0.9623 - recall: 0.9583 - val_loss: 0.3863 - val_categorical_accuracy: 0.8850 - val_accuracy: 0.8850 - val_auc: 0.9822 - val_precision: 0.8901 - val_recall: 0.8825\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 30s 42ms/step - loss: 0.0710 - categorical_accuracy: 0.9760 - accuracy: 0.9760 - auc: 0.9990 - precision: 0.9767 - recall: 0.9753 - val_loss: 0.3996 - val_categorical_accuracy: 0.8945 - val_accuracy: 0.8945 - val_auc: 0.9804 - val_precision: 0.8963 - val_recall: 0.8900\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 30s 42ms/step - loss: 0.0574 - categorical_accuracy: 0.9791 - accuracy: 0.9791 - auc: 0.9995 - precision: 0.9797 - recall: 0.9781 - val_loss: 0.4648 - val_categorical_accuracy: 0.8840 - val_accuracy: 0.8840 - val_auc: 0.9765 - val_precision: 0.8869 - val_recall: 0.8820\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 30s 42ms/step - loss: 0.0491 - categorical_accuracy: 0.9815 - accuracy: 0.9815 - auc: 0.9994 - precision: 0.9821 - recall: 0.9810 - val_loss: 0.5086 - val_categorical_accuracy: 0.8775 - val_accuracy: 0.8775 - val_auc: 0.9731 - val_precision: 0.8817 - val_recall: 0.8760\n",
      "Epoch 7/100\n",
      "719/720 [============================>.] - ETA: 0s - loss: 0.0519 - categorical_accuracy: 0.9800 - accuracy: 0.9800 - auc: 0.9996 - precision: 0.9807 - recall: 0.9797Restoring model weights from the end of the best epoch: 2.\n",
      "720/720 [==============================] - 29s 41ms/step - loss: 0.0519 - categorical_accuracy: 0.9800 - accuracy: 0.9800 - auc: 0.9996 - precision: 0.9807 - recall: 0.9797 - val_loss: 0.5394 - val_categorical_accuracy: 0.8805 - val_accuracy: 0.8805 - val_auc: 0.9732 - val_precision: 0.8823 - val_recall: 0.8805\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_, y_train_, callbacks=[callbacks], epochs=100, validation_data=(X_valid_, y_valid_), batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5430100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('C:/Users/lenovo/DATA SCIENCE PROJECTS/MODEL/EMOTION DETECTION/weights.h5', save_format='HDF5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f6b6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emotions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da1749e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 2s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14819051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 2s 11ms/step - loss: 0.2787 - categorical_accuracy: 0.8908 - accuracy: 0.8908 - auc: 0.9911 - precision: 0.8987 - recall: 0.8847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2786557376384735,\n",
       " 0.89083331823349,\n",
       " 0.89083331823349,\n",
       " 0.9910821914672852,\n",
       " 0.8987020254135132,\n",
       " 0.8847222328186035]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35dcdb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 5s 11ms/step - loss: 0.0775 - categorical_accuracy: 0.9727 - accuracy: 0.9727 - auc: 0.9991 - precision: 0.9748 - recall: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0774773359298706,\n",
       " 0.9727083444595337,\n",
       " 0.9727083444595337,\n",
       " 0.9990627765655518,\n",
       " 0.9747700095176697,\n",
       " 0.9712499976158142]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c71e5fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for to'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = ['for', 'to']\n",
    "\n",
    "new = ' '.join(i for i in lis)\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77da781",
   "metadata": {},
   "source": [
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(token, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
